<h1> Veena Ramesh </h1> 
<i> github: veenaramesh </i> 
Computer Science and Statistics, College of Arts and Science 
<br> 
<br> 
<br> 
> There seems to be a huge disconnect between policy and technology, where those in Big Tech do not understand the importance of policy
and those working on policy do not understand how emerging tech works. I do not want to be in either of those categories. 

<h3> Class Three - Algorithmic Bias </h3> 

[Flawed Algorithms are grading millions of students' essays](https://www.vice.com/en_us/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=76444586&_hsenc=p2ANqtz-86J-dM6Yg6jGk3q5m9vpYEAWrt3HONfUloyHgL-gTruZWIgXddqop4Ik21u9kb8gEFegK8xbtfTKquojndZL5W1erjHg&_hsmi=76444586)
<br> 
Several companies that sell standardized tests are using NLPs to assess critical
writing skills; however, Vice Motherboard found that these programs show significant
bias against those who speak English as a second-language (usually minority populations.)
Additionally, these models gave better scores who used "larger" vocabulary, even if
it did not mean anything in context. 21 states use NLPs to grade these standardized
tests in public schools. 
<br> 
Almost every university and school uses standardized testing to determine success
for millions of students. These models could be preventing access to rightfully-
earned opportunities. 

