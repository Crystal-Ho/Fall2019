## Name
Github Username:katherineweinschenk

Field of Study, Year: CS and Anthropology - 3rd Year

> I'm taking this class because I think that computer scientists are trained for efficiency, not ethics. I want to learn the adverse effects of technology so I don't contribute to the problem and so I can advocate for more critical thinking in the field.


### Class 1 - Content Moderation (free speech restrictions) on the Internet

[YouTube’s arbitrary standards: Stars keep making money even after breaking the rules](https://www.washingtonpost.com/technology/2019/08/09/youtubes-arbitrary-standards-stars-keep-making-money-even-after-breaking-rules/?noredirect=on)

Media Justification: This week's topic reminded me of the Logan Paul Youtube scandal from this past year, so I looked for an article about it. This Washington Post article details the perspective of moderators at Youtube who have noticed Youtube's unfair content moderation rules. It explains that the lack of equality mostly surrounds issues with money and advertising: the main things that social media platforms are concerned with. One moderator wrote “Our responsibility was never to the creators or to the users — it was to the advertisers" - which should have been included in the list of problems with content moderation article. 

### Class 2 - Algorithmic Bias

[AI-powered cameras become new tool against mass shootings](https://www.latimes.com/business/story/2019-09-04/ai-powered-cameras-become-new-tool-against-mass-shootings)

Media Justification: This article, to me, is so ridiculous. We have resorted to artificial intelligence, which is just a lot of matrix math, to identify and "stop" school shooters. "Intelligent video" is supposed to be able to identify not only weapons, but "violent" facial expressions. I'm not sure what this even means, and overall, it's avoiding the main issue, which is that Americans have very easy access to guns. Also, data-driven racism could make this technology go horribly wrong. For some reason, we really have trouble identifying the root cause of problems, and at the same time put so much trust in non-sentient bodies (computers and guns!).

### Class 3 - Regulating Tech Monopolies

[Adam Ruins Everything - How the Government Created Tech Monopolies | truTV](https://www.youtube.com/watch?v=mid1VvK9Xpgs)

[Please Regulate Us: Tech Firms Need More Regulation](https://www.theatlantic.com/ideas/archive/2019/09/please-regulate-us/597613/)

This short Adam Ruins Everything clip reveals a small part of the relationship between government and tech companies that I have never really considered. The concept that tech companies exist outside of the public sphere is false; according to this video, the US government invested $4.5 million in Google and a half a billion dollars in Tesla to help them begin. Despite this, Adam points out that these companies don't pay the taxes they should, and therefore have a less reciprocal relationship with the govenment. In the Atlantic article, the author (president of Microsoft, Brad Smith), points out that "Many in tech circles have asserted that people in government don’t understand enough about technology to regulate it properly—even while tech companies have benefited from all manner of government funding and support." In my opinion, by accepting government funding, you acknowledge that you have an obligation to the government. The government should be expected to regulate these companies as they are not separate actors. On another note, it's interesting that the President of Microsoft wrote this article, but it makes sense at the end of the article. He ends with the statement, "Technology innovation is not going to slow down. The work to manage it needs to speed up," placing the responsibility on regulators, rather than innovators.

### Class 4 - Anonymity 

[Google wins case over EU’s ‘right to be forgotten’ rules](https://www.washingtonpost.com/world/europe/eu-top-court-rules-in-favor-of-google-on-search-engine-issue/2019/09/24/aeb78c9e-dea4-11e9-be7f-4cc85017c36f_story.html)

This seems like the most relevant topic to discuss, considering that the EU's highest court ruled only two days ago that the "right to be forgotten" rule does not apply outside of the EU. This means that people cannot request for their information to be removed beyond the internet in the EU (which seems a little arbitrary to me). However, the court also ruled that search engines must discourage internet users from going outside of the EU to find the deleted information from inside the EU. This relates to our conversation about how to deal with a "borderless" internet in a heavily bordered world. 



### Class 5 - Data Ownership and Privacy

[DATA AS A PROPERTY RIGHT](https://www.yang2020.com/policies/data-property-right/)

After some research, I came across Andrew Yang's 7 points for implementing data regulations. He, too, describes data in terms of ownership and encourages individual ownership of data. His proposed "rights" reflect ideas that are present in the GDRP, such as the right to be forgotten. These rights also include the right to be informed if the ownership of your data changes hands, the right to be told how a website uses your data, etc. What interests me is his concluding paragraph in which he mentions the ideas of informed consent and just compensation. As academic researchers are held to these ethical standards, corporate researchers should only be allowed to evaluate data if it is collected with informed consent, and if the research subjects are compensated (in Yang's terms, monetarily) for their data/information.

### Class 6 - Surveillance Capitalism

[Here are 4 steps to defend yourself from Big Tech’s greed-driven behavioral manipulation](https://www.alternet.org/2019/09/here-are-4-steps-to-defend-yourself-from-big-techs-greed-driven-behavioral-manipulation/)

This article references Zuboff's book and responds to it by proposing 4 ways to avoid companies' behavioral manipulation. The four points are: 1) join the resistance, 2) minimize your interaction with technology, 3) do less phone-orientation activities, and 4) join an activist group. I thought this was interesting because Zuboff did not propose solutions to surveillance capitalism, but rather sought to define it. However, I don't agree with the simplicity of this article's answers. The article suggests that it is the individual's obligation to protect themself from exploitation and manipulation, which does nothing to dismantle the system but places more anxiety on the individual. These technologies that have been adopted for surveillance capitalism have been designed to create dependency, and it should be the duty of the owners of surveillance capital not manipulate. At the same time, I understand that if one is feeling frustrated/helpless against this beast, it could be easier to withdraw from participation than to propose and fight for reform.



### Class 7 - Social Media and Democracy

[CSPAN on Twitter](https://twitter.com/cspan/status/1187098428737753091?s=20)

I love the energy AOC has during this questioning. She is unafraid to call Zuckerburg out on certain things - "in your ongoing dinner parties with far right figures..." - making him uncomfortable with what we all are already uncomfortable. It's interesting that his response to the question of taking content down is "yes, if it causes violence, harm, or voter supression," just tacking on the main issue at the end as if he's trying to mask his answer. I especially liked "I think lying is bad"; he's being condescending about morality and placing the job of fact-checking on individuals, while placing the blame of lying on those who spread disinformation instead of his company for propogating it. I think the topic of free speech is fascinating in this context. We need to redefine what free speech is and what safety is to maintain a democracy.



